import boto3
import sagemaker
from sagemaker import get_execution_role
import time

# Initialize boto3 client and SageMaker session
sagemaker_client = boto3.client("sagemaker")
sagemaker_session = sagemaker.Session()
role = get_execution_role()

# Define S3 bucket and model artifact
bucket = "your-s3-bucket-name"  # Replace with your bucket
model_artifact = "s3://your-s3-bucket-name/path-to-model/model.tar.gz"  # Replace with your model path
image_uri = "your-ecr-image-uri"  # Replace with container image URI for inference

# Model name
model_name = "serverless-model-" + str(int(time.time()))

# Step 1: Create Model
response = sagemaker_client.create_model(
    ModelName=model_name,
    PrimaryContainer={
        "Image": image_uri,
        "ModelDataUrl": model_artifact,
        "Environment": {
            "SAGEMAKER_PROGRAM": "inference.py",  # Entry-point script
            "SAGEMAKER_SUBMIT_DIRECTORY": model_artifact,
        }
    },
    ExecutionRoleArn=role,
)

print("Model created:", response["ModelArn"])

# Step 2: Create Endpoint Configuration for Serverless Inference
endpoint_config_name = "serverless-endpoint-config-" + str(int(time.time()))

response = sagemaker_client.create_endpoint_config(
    EndpointConfigName=endpoint_config_name,
    ProductionVariants=[
        {
            "VariantName": "AllTraffic",
            "ModelName": model_name,
            "ServerlessConfig": {
                "MemorySizeInMB": 2048,  # Memory size in MB
                "MaxConcurrency": 5,    # Maximum concurrency
            },
        }
    ],
)

print("Endpoint Config created:", response["EndpointConfigArn"])

# Step 3: Create Endpoint
endpoint_name = "serverless-endpoint-" + str(int(time.time()))

response = sagemaker_client.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=endpoint_config_name,
)

print("Endpoint creation started. Endpoint Name:", endpoint_name)

# Wait for the endpoint to be in service
def wait_for_endpoint(endpoint_name):
    print("Waiting for endpoint to be in service...")
    while True:
        response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)
        status = response["EndpointStatus"]
        print("Endpoint status:", status)
        if status == "InService":
            break
        elif status == "Failed":
            raise Exception("Endpoint creation failed:", response)
        time.sleep(30)

wait_for_endpoint(endpoint_name)

print(f"Endpoint {endpoint_name} is now InService")

# Step 4: Invoke the Endpoint
# Replace with your input payload
import json

test_payload = {"input_data": [1, 2, 3]}  # Example payload

response = sagemaker_client.invoke_endpoint(
    EndpointName=endpoint_name,
    Body=json.dumps(test_payload),
    ContentType="application/json",
)

print("Predictions:", response["Body"].read().decode("utf-8"))

# Step 5: Cleanup Resources (Optional)
# Uncomment the following lines to delete resources
# sagemaker_client.delete_endpoint(EndpointName=endpoint_name)
# sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)
# sagemaker_client.delete_model(ModelName=model_name)